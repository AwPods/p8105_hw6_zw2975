p8105_hw6_zw2975
================
Zhiyu Wei
2024-11-14

## Problem 1

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

    ## using cached file: C:\Users\wa200\AppData\Local/R/cache/R/rnoaa/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2024-12-01 12:12:18.57505 (8.685)

    ## file min/max dates: 1869-01-01 / 2024-11-30

``` r
n_sample = 5000

# function for sampling
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}


boot_straps = 
  tibble(strap_number = 1:n_sample) |> 
  mutate(
    strap_sample = map(strap_number, ~ boot_sample(df = weather_df))
  )

# linear regression fit
extract = function(df) {
  model = lm(tmax ~ tmin, data = df)
  r_squared = broom::glance(model)$r.squared # Extract R square
  beta = broom::tidy(model) # Extract coefficients and calculate log(β0 * β1)
  log_beta = log(beta$estimate[1] * beta$estimate[2])
  tibble(r_squared = r_squared, log_beta = log_beta)
}

# Apply the function to each bootstrap sample
boot_results = boot_straps |> 
  mutate(
    results = purrr::map(strap_sample, extract)
  ) |> 
  unnest(results)
```

``` r
# Plot R square distribution
ggplot(boot_results, aes(x = r_squared)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.6) +
  labs(
    title = "Bootstrap Distribution of R2 Estimates",
    x = "R squared",
    y = "Frequency"
  )
```

![](p8105_hw6_zw2975_files/figure-gfm/plot%20estimates-1.png)<!-- -->

``` r
# Plot log(β0 * β1) distribution
ggplot(boot_results, aes(x = log_beta)) +
  geom_histogram(bins = 30, fill = "red", alpha = 0.6) +
  labs(
    title = "Distribution of log(β0 * β1) estimates",
    x = "log(β0 * β1)",
    y = "Frequency"
  ) 
```

![](p8105_hw6_zw2975_files/figure-gfm/plot%20estimates-2.png)<!-- -->

###### Describe in word

Both distributions are normally distributed. The R squared distribution
has the highest number of observations around 0.91 that has slightly
less than 500 observations. The highest R squared does not exceed 0.94
and the lowest does not go lower than 0.87. This also suggests that
there is a high linear correlation between tmin and tmax in the linear
regression model.

For the log(B0*B1) distribution, the highest log(B0*B1) lies around 2.2
with more than 500 observations. The highest observation does not exceed
2.125 and the lowest does not go under 1.925.

``` r
ci_r_squared = quantile(boot_results$r_squared, c(0.025, 0.975))
ci_log_beta = quantile(boot_results$log_beta, c(0.025, 0.975))

print(ci_r_squared)
```

    ##      2.5%     97.5% 
    ## 0.8938241 0.9273183

``` r
print(ci_log_beta)
```

    ##     2.5%    97.5% 
    ## 1.965666 2.057098

## Problem 2

``` r
# import data
homic = read.csv("./data/homicide-data.csv")
```

``` r
# create city_state variable, omit places, only keep desired races, numeric victim_age
homic = mutate(homic,
           city_state= paste(city, state, sep=', ')) |>
filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")))|>
  filter(victim_race %in% c("White", "Black")) |>
  mutate(victim_age = as.numeric(victim_age))

# create binary for case status
homic = homic |>
  mutate(resolved = ifelse(disposition == "Closed by arrest", 1, 0))

# create a Baltimore dataset
balt = homic |>
  filter(city_state == "Baltimore, MD")
```

#### Logistic Regression Model

``` r
# predictors are sex, age, and race of victims (in Baltimore, MD)
balt_fit = glm(resolved ~ victim_age + victim_race + victim_sex, data = balt, family = binomial()) 

summary(balt_fit)
```

    ## 
    ## Call:
    ## glm(formula = resolved ~ victim_age + victim_race + victim_sex, 
    ##     family = binomial(), data = balt)
    ## 
    ## Coefficients:
    ##                   Estimate Std. Error z value Pr(>|z|)    
    ## (Intercept)       0.309981   0.171295   1.810   0.0704 .  
    ## victim_age       -0.006727   0.003324  -2.024   0.0430 *  
    ## victim_raceWhite  0.841756   0.174716   4.818 1.45e-06 ***
    ## victim_sexMale   -0.854463   0.138176  -6.184 6.26e-10 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 3567.9  on 2752  degrees of freedom
    ## Residual deviance: 3492.7  on 2749  degrees of freedom
    ## AIC: 3500.7
    ## 
    ## Number of Fisher Scoring iterations: 4

``` r
# Extracing CIs and OR
balt_results = broom::tidy(balt_fit, conf.int = TRUE) |>
  filter(term == "victim_sexMale") |>
  mutate(odds_ratio = exp(estimate),
         conf.low = exp(conf.low),
         conf.high = exp(conf.high))

print(balt_results)
```

    ## # A tibble: 1 × 8
    ##   term       estimate std.error statistic  p.value conf.low conf.high odds_ratio
    ##   <chr>         <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>      <dbl>
    ## 1 victim_se…   -0.854     0.138     -6.18 6.26e-10    0.324     0.558      0.426

``` r
city_results = homic |>
  group_by(city_state) |>
  nest() |>
  mutate(
    model = purrr::map(data, ~ glm(resolved ~ victim_age + victim_sex + victim_race, 
                            data = ., 
                            family = binomial)),
    tidy_model = purrr::map(model, ~ broom::tidy(.x, conf.int = TRUE)),
    odds_ratios = purrr::map(tidy_model, ~ .x |>
                        filter(term == "victim_sexMale") |>
                        mutate(odds_ratio = exp(estimate),
                               conf.low = exp(conf.low),
                               conf.high = exp(conf.high)))
  ) |>
  unnest(odds_ratios) |>
  select(city_state, odds_ratio, conf.low, conf.high)
```

#### Plot of OR and CIs

``` r
ggplot(city_results, aes(x = reorder(city_state, odds_ratio), y = odds_ratio)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2, color = "gray") + 
  labs(
    title = "Adjusted Odds Ratios and CIs for Resolved Homicides by City",
    y = "Odds Ratio and CIs (male compared to female)",
    x = "City"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1)) # Rotate city names to save space
```

![](p8105_hw6_zw2975_files/figure-gfm/plot%20city%20results-1.png)<!-- -->

###### Comment

New York has the lowest odds ratio and also a relatively small range of
CI for the odds ratio. It is also obvious that the CI increases in size
as the odds ratio increases for most cities. The highest odds ratio of
male vs. female resolved crime is from Albuquerque, NM. The highest odds
ratio does not exceed 2 and most of the odds ratio lies between 0 and 1,
which means that there are more resolved crime when victim’s sex is
female for most cases.

## Problem 3

``` r
bw = read.csv("./data/birthweight.csv")
```

``` r
# changed numbers to labelled entries
bw = bw |>
set_value_labels(
  frace = c("White" = 1, "Black" = 2, "Asian" = 3, "Puerto Rican" = 4, "Other" = 8, "Unknown" = 9),
  mrace = c("White" = 1, "Black" = 2, "Asian" = 3, "Puerto Rican" = 4, "Other" = 8, "Unknown" = 9))

# changed labelled entries to factor
bw = bw |>
  mutate_if(is.labelled, to_factor)
```

``` r
# Regression model
bw_model = lm(bwt ~ gaweeks + delwt + smoken + babysex + mrace * frace, data = bw)

summary(bw_model)
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ gaweeks + delwt + smoken + babysex + mrace * 
    ##     frace, data = bw)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1691.77  -259.21     4.06   270.49  1501.77 
    ## 
    ## Coefficients: (1 not defined because of singularities)
    ##                                      Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)                          423.9941    91.6925   4.624 3.87e-06 ***
    ## gaweeks                               54.6678     2.0992  26.042  < 2e-16 ***
    ## delwt                                  5.8988     0.2962  19.914  < 2e-16 ***
    ## smoken                               -11.8244     0.9029 -13.095  < 2e-16 ***
    ## babysex                              -90.1915    12.9283  -6.976 3.49e-12 ***
    ## mraceBlack                          -276.4213   160.7053  -1.720   0.0855 .  
    ## mraceAsian                          -362.2515   212.4741  -1.705   0.0883 .  
    ## mracePuerto Rican                   -130.9048   113.8108  -1.150   0.2501    
    ## fraceBlack                          -120.9991   106.5775  -1.135   0.2563    
    ## fraceAsian                          -153.2831   150.3417  -1.020   0.3080    
    ## fracePuerto Rican                   -195.1451   110.1275  -1.772   0.0765 .  
    ## fraceOther                          -133.4604   134.5450  -0.992   0.3213    
    ## mraceBlack:fraceBlack                100.1548   192.8250   0.519   0.6035    
    ## mraceAsian:fraceBlack                435.1351   486.4242   0.895   0.3711    
    ## mracePuerto Rican:fraceBlack          16.6713   263.1648   0.063   0.9495    
    ## mraceBlack:fraceAsian                441.2955   478.0301   0.923   0.3560    
    ## mraceAsian:fraceAsian                466.2440   269.5277   1.730   0.0837 .  
    ## mracePuerto Rican:fraceAsian         104.9440   464.3978   0.226   0.8212    
    ## mraceBlack:fracePuerto Rican         148.4038   245.7219   0.604   0.5459    
    ## mraceAsian:fracePuerto Rican         929.6352   487.0814   1.909   0.0564 .  
    ## mracePuerto Rican:fracePuerto Rican  187.5553   160.6133   1.168   0.2430    
    ## mraceBlack:fraceOther                535.7351   322.5029   1.661   0.0967 .  
    ## mraceAsian:fraceOther                466.1802   493.5156   0.945   0.3449    
    ## mracePuerto Rican:fraceOther               NA         NA      NA       NA    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 424.3 on 4319 degrees of freedom
    ## Multiple R-squared:  0.317,  Adjusted R-squared:  0.3135 
    ## F-statistic:  91.1 on 22 and 4319 DF,  p-value: < 2.2e-16

``` r
# Add predictions and residuals to the data
bw = bw |>
  add_predictions(bw_model, var = "fitted") |>
  add_residuals(bw_model, var = "residuals")

# Plot residuals against fitted values
ggplot(bw, aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs. Fitted Values",
    x = "Fitted Values",
    y = "Residuals")
```

![](p8105_hw6_zw2975_files/figure-gfm/fitted%20vs.%20residuals-1.png)<!-- -->

``` r
model1 = lm(bwt ~ blength + gaweeks, data = bw)

model2 = lm(bwt ~ bhead * blength * babysex, data = bw)
```

``` r
cv_df <- crossv_mc(bw, n = 100, test = 0.2)

# convert train and test sets to tibbles
cv_df <- cv_df |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

# fit models on training data
cv_df <- cv_df |> 
  mutate(
    bw_mod = map(train, ~ lm(bwt ~ gaweeks + delwt + smoken + babysex + mrace, data = .x)),
    m1_mod = map(train, ~ gam(bwt ~ s(blength) + s(gaweeks), data = .x)),
    m2_mod = map(train, ~ gam(bwt ~ s(bhead, blength, babysex), data = .x)))

# function to calculate RMSE
rmse <- function(model, data) {
  preds <- predict(model, newdata = data)
  sqrt(mean((data$bwt - preds)^2))
}

# get RMSE for every model
cv_df <- cv_df |> 
  mutate(
    rmse_bw = map2_dbl(bw_mod, test, ~ rmse(.x, .y)),
    rmse_m1 = map2_dbl(m1_mod, test, ~ rmse(.x, .y)),
    rmse_m2 = map2_dbl(m2_mod, test, ~ rmse(.x, .y))
  )


# summarize RMSE for every model
rmse_summary <- cv_df |> 
  summarise(
    mean_rmse_bw = mean(rmse_bw),
    mean_rmse_m1 = mean(rmse_m1),
    mean_rmse_m2 = mean(rmse_m2),
    sd_rmse_bw = sd(rmse_bw),
    sd_rmse_m1 = sd(rmse_m1),
    sd_rmse_m2 = sd(rmse_m2)
  )

print(rmse_summary)
```

    ## # A tibble: 1 × 6
    ##   mean_rmse_bw mean_rmse_m1 mean_rmse_m2 sd_rmse_bw sd_rmse_m1 sd_rmse_m2
    ##          <dbl>        <dbl>        <dbl>      <dbl>      <dbl>      <dbl>
    ## 1         424.         324.         284.       9.46       11.7       6.79

###### Comment

The summarized RMSE has proven that Model 2, which uses head
circumference, length, sex, and all interactions (including the
three-way interaction), has the best fit on the data. The RMSE is the
second lowest for Model 1, which uses length at birth and gestational
age as predictors with only the main effects. My model, however, has the
highest RMSE, which means it has the worst fit. It would probably be
better to add more interaction terms to the model for a better fit over
the data.
